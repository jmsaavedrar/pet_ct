{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7a7a00-6fe2-4196-b1f7-1994012b8b2d",
   "metadata": {},
   "source": [
    "# Análisis de características Radiométricas\n",
    "\n",
    "Se procesan las características radiométricas y se experimentan para obtener el resultado en modelos\n",
    "**Roberto Araya**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c398e3d6-6426-4e73-88f8-1efa3c6763c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, SelectPercentile, f_regression\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "27844f78-7495-4c39-b150-e2c8377f876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameteres\n",
    "binwidth = 5\n",
    "sigma = [1,2,3]\n",
    "normalize= True\n",
    "imageTypes = ['Original', 'LoG', 'Square', 'SquareRoot']\n",
    "\n",
    "sm_radiometrics_file = f'santamaria_data_all__binwidth_{binwidth}_sigma_{sigma}_imtype_{imageTypes}_normalize_{normalize}.csv'\n",
    "sm_radiometrics_file='santamaria_data_all__binwidth_5_sigma_[1, 2, 3]_normalize_True.csv'\n",
    "sm_radiometrics = pd.read_csv(sm_radiometrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c2899120-8f97-47cf-824b-e7d8bec3f054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>SEXO_MASCULINO</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>FECHA_CIRUGIA</th>\n",
       "      <th>BIOPSIA_QX_PULMONAR</th>\n",
       "      <th>BIOPSIA_FBC-EBUS</th>\n",
       "      <th>BIOPSIA_OTRO_SITIO</th>\n",
       "      <th>RESULTADO_BP</th>\n",
       "      <th>BP_COMPLETA</th>\n",
       "      <th>HISTOLOGIA</th>\n",
       "      <th>...</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_ZoneEntropy</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_ZonePercentage</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_ZoneVariance</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Busyness</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Coarseness</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Complexity</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Contrast</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sm_001</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>BIOPSIAS TRANSBRONQUIALES-ENDOBRONQUIALES: VAR...</td>\n",
       "      <td>Fecha Informe         : 26/03/2018\\n\\n \\n\\nINF...</td>\n",
       "      <td>ADENOCARCINOMA</td>\n",
       "      <td>...</td>\n",
       "      <td>3.223680e-10</td>\n",
       "      <td>3.223680e-10</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sm_002</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2017-05-19 00:00:00</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>1.- PUNCION ENDOSONOGRAFICA DE LINFONODOS 4L: ...</td>\n",
       "      <td>Fecha Informe         : 17/02/2017\\n \\n\\n\\n\\nI...</td>\n",
       "      <td>ADENOCARCINOMA</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056094e+00</td>\n",
       "      <td>3.742753e-01</td>\n",
       "      <td>2.663533e+00</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>2.898075e+06</td>\n",
       "      <td>728.494377</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.270414</td>\n",
       "      <td>0.065973</td>\n",
       "      <td>0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sm_003</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2017-07-05 00:00:00</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>1.- VENTANA AORTOPULMUNAR : METASTASIS DE ADEN...</td>\n",
       "      <td>Fecha Informe : 10/07/2017\\n\\n\\n\\nINFORME ANAT...</td>\n",
       "      <td>ADENOCARCINOMA</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110370e-06</td>\n",
       "      <td>1.110370e-06</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sm_004</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>2017-05-05 00:00:00</td>\n",
       "      <td>SI</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>2.- PUNCION EBUS LINFONODO 4L: ABUNDANTE MATER...</td>\n",
       "      <td>Fecha Informe : 04/01/2017\\n\\nINFORME ANATOMO-...</td>\n",
       "      <td>ADENOCARCINOMA</td>\n",
       "      <td>...</td>\n",
       "      <td>2.114469e-09</td>\n",
       "      <td>2.114469e-09</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sm_005</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>SI</td>\n",
       "      <td>NO</td>\n",
       "      <td>SI</td>\n",
       "      <td>2.- LOBECTOMIA SUPERIOR IZQUIERDA (124 GR.): A...</td>\n",
       "      <td>Fecha Informe : 11 DE ENERO DE 2016\\n\\nINFORME...</td>\n",
       "      <td>ADENOCARCINOMA</td>\n",
       "      <td>...</td>\n",
       "      <td>6.834896e-01</td>\n",
       "      <td>3.172786e-01</td>\n",
       "      <td>3.077820e+00</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>2.531202e+07</td>\n",
       "      <td>728.918817</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.140840</td>\n",
       "      <td>0.027048</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PATIENT_ID  SEXO_MASCULINO  EDAD        FECHA_CIRUGIA BIOPSIA_QX_PULMONAR  \\\n",
       "0     sm_001               1    70                  NaN                  NO   \n",
       "1     sm_002               0    49  2017-05-19 00:00:00                  SI   \n",
       "2     sm_003               0    43  2017-07-05 00:00:00                  NO   \n",
       "3     sm_004               0    54  2017-05-05 00:00:00                  SI   \n",
       "4     sm_005               0    44  2016-01-06 00:00:00                  SI   \n",
       "\n",
       "  BIOPSIA_FBC-EBUS BIOPSIA_OTRO_SITIO  \\\n",
       "0               SI                 NO   \n",
       "1               SI                 NO   \n",
       "2               NO                 SI   \n",
       "3               SI                 NO   \n",
       "4               NO                 SI   \n",
       "\n",
       "                                        RESULTADO_BP  \\\n",
       "0  BIOPSIAS TRANSBRONQUIALES-ENDOBRONQUIALES: VAR...   \n",
       "1  1.- PUNCION ENDOSONOGRAFICA DE LINFONODOS 4L: ...   \n",
       "2  1.- VENTANA AORTOPULMUNAR : METASTASIS DE ADEN...   \n",
       "3  2.- PUNCION EBUS LINFONODO 4L: ABUNDANTE MATER...   \n",
       "4  2.- LOBECTOMIA SUPERIOR IZQUIERDA (124 GR.): A...   \n",
       "\n",
       "                                         BP_COMPLETA      HISTOLOGIA  ...  \\\n",
       "0  Fecha Informe         : 26/03/2018\\n\\n \\n\\nINF...  ADENOCARCINOMA  ...   \n",
       "1  Fecha Informe         : 17/02/2017\\n \\n\\n\\n\\nI...  ADENOCARCINOMA  ...   \n",
       "2  Fecha Informe : 10/07/2017\\n\\n\\n\\nINFORME ANAT...  ADENOCARCINOMA  ...   \n",
       "3  Fecha Informe : 04/01/2017\\n\\nINFORME ANATOMO-...  ADENOCARCINOMA  ...   \n",
       "4  Fecha Informe : 11 DE ENERO DE 2016\\n\\nINFORME...  ADENOCARCINOMA  ...   \n",
       "\n",
       "   torax3d_wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                       3.223680e-10          \n",
       "1                                       1.056094e+00          \n",
       "2                                       1.110370e-06          \n",
       "3                                       2.114469e-09          \n",
       "4                                       6.834896e-01          \n",
       "\n",
       "  torax3d_wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis  \\\n",
       "0                                       3.223680e-10        \n",
       "1                                       3.742753e-01        \n",
       "2                                       1.110370e-06        \n",
       "3                                       2.114469e-09        \n",
       "4                                       3.172786e-01        \n",
       "\n",
       "   torax3d_wavelet-LLL_glszm_ZoneEntropy  \\\n",
       "0                          -3.203427e-16   \n",
       "1                           2.663533e+00   \n",
       "2                          -3.203427e-16   \n",
       "3                          -3.203427e-16   \n",
       "4                           3.077820e+00   \n",
       "\n",
       "   torax3d_wavelet-LLL_glszm_ZonePercentage  \\\n",
       "0                                  0.000018   \n",
       "1                                  0.001273   \n",
       "2                                  0.001054   \n",
       "3                                  0.000046   \n",
       "4                                  0.000602   \n",
       "\n",
       "   torax3d_wavelet-LLL_glszm_ZoneVariance torax3d_wavelet-LLL_ngtdm_Busyness  \\\n",
       "0                            0.000000e+00                           0.000000   \n",
       "1                            2.898075e+06                         728.494377   \n",
       "2                            0.000000e+00                           0.000000   \n",
       "3                            0.000000e+00                           0.000000   \n",
       "4                            2.531202e+07                         728.918817   \n",
       "\n",
       "   torax3d_wavelet-LLL_ngtdm_Coarseness torax3d_wavelet-LLL_ngtdm_Complexity  \\\n",
       "0                        1000000.000000                             0.000000   \n",
       "1                              0.000856                             0.270414   \n",
       "2                        1000000.000000                             0.000000   \n",
       "3                        1000000.000000                             0.000000   \n",
       "4                              0.000534                             0.140840   \n",
       "\n",
       "  torax3d_wavelet-LLL_ngtdm_Contrast torax3d_wavelet-LLL_ngtdm_Strength  \n",
       "0                           0.000000                           0.000000  \n",
       "1                           0.065973                           0.000842  \n",
       "2                           0.000000                           0.000000  \n",
       "3                           0.000000                           0.000000  \n",
       "4                           0.027048                           0.000505  \n",
       "\n",
       "[5 rows x 4646 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_radiometrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a6990-4363-4710-839a-45aeeae68ba6",
   "metadata": {},
   "source": [
    "## Procesamiento de datos\n",
    "- Se eliminan columnas no relevantes.\n",
    "- Se vectorizan las características compuestas por categorías de *strings* con el método *one-hot-encoding*.\n",
    "- Se eliminan las columnas que posean alguna fila con valor nulo (INVESIGAR ESTOS CASOS, CASOS SIN EXAMENES TORAX3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "63b61e61-3d3c-450e-916b-01edda2c0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_drop_columns = ['PATIENT_ID', 'FECHA_CIRUGIA', 'BIOPSIA_QX_PULMONAR', 'BIOPSIA_FBC-EBUS', 'BIOPSIA_OTRO_SITIO', 'RESULTADO_BP', 'BP_COMPLETA', 'HISTOLOGIA', 'MUTACION_EGFR', 'MUTACION_PDL-1', 'MUTACION_ROS', 'RECIDIVA', 'COMENTARIO', '3D_TORAX_SEG', 'PET_SEG', 'BODY_CT_SEG']\n",
    "images_columns = ['diagnostics_Configuration_EnabledImageTypes', 'diagnostics_Configuration_Settings', \n",
    "                  'diagnostics_Image-original_Dimensionality', 'diagnostics_Mask-original_BoundingBox', \n",
    "                  'diagnostics_Versions_PyRadiomics', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Image-original_Hash', \n",
    "                  'diagnostics_Image-original_Size', 'diagnostics_Image-original_Spacing', 'diagnostics_Mask-original_Hash', \n",
    "                  'diagnostics_Mask-original_Size', 'diagnostics_Mask-original_Spacing', 'diagnostics_Versions_Numpy', \n",
    "                  'diagnostics_Versions_PyWavelet', 'diagnostics_Versions_Python', 'diagnostics_Versions_SimpleITK', \n",
    "                  'diagnostics_Image-interpolated_Size', 'diagnostics_Image-interpolated_Spacing', 'diagnostics_Mask-interpolated_BoundingBox', \n",
    "                  'diagnostics_Mask-interpolated_CenterOfMass', 'diagnostics_Mask-interpolated_CenterOfMassIndex', 'diagnostics_Mask-interpolated_Size',\n",
    "                  'diagnostics_Mask-interpolated_Spacing']\n",
    "\n",
    "exam_types = ['body_', 'pet_', 'torax3d_']\n",
    "images_columns = [exam + s for s in images_columns for exam in exam_types]\n",
    "\n",
    "# extra columns that are not relevant\n",
    "extra_columns = ['ALK', 'MUTACION_ALK', 'PDL-1','ROS', 'ADENOPATIAS', 'STAGE', 'TAMAÑO_BP_mm', 'TAMAÑO_CT_mm']\n",
    "\n",
    "drop_columns = original_drop_columns+images_columns+extra_columns\n",
    "sm_radiometrics = sm_radiometrics.drop(columns=drop_columns)\n",
    "\n",
    "# Apply one-hot encoding to selected columns\n",
    "#sm_radiometrics = pd.get_dummies(sm_radiometrics, columns=['ADENOPATIAS', 'STAGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "deac67ee-ad83-48fb-b113-eaf47caa28f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['body_diagnostics_Mask-original_CenterOfMass', 'pet_diagnostics_Mask-original_CenterOfMass', 'torax3d_diagnostics_Mask-original_CenterOfMass']\n"
     ]
    }
   ],
   "source": [
    "td_values = [s+'diagnostics_Mask-original_CenterOfMass' for s in exam_types]\n",
    "print(td_values)\n",
    "\n",
    "for dim in td_values:\n",
    "    # Use str.extract to separate the string into three columns with specified suffixes\n",
    "    extracted_values = sm_radiometrics[dim].str.extract(r'\\(([^,]+), ([^,]+), ([^)]+)\\)')\n",
    "    extracted_values.columns = [f'{dim}_x', f'{dim}_y', f'{dim}_z']\n",
    "\n",
    "    # Convert the columns to numeric (they are currently strings)\n",
    "    extracted_values = extracted_values.apply(pd.to_numeric)\n",
    "\n",
    "    # Concatenate the original DataFrame with the extracted values\n",
    "    sm_radiometrics = pd.concat([sm_radiometrics, extracted_values], axis=1)\n",
    "\n",
    "# Drop the original column with the (x, y, z) format\n",
    "sm_radiometrics = sm_radiometrics.drop(td_values, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55718ca5-8816-4eac-8325-564e2ed83e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print columns with NaN values\n",
    "columns_with_nan = sm_radiometrics.columns[sm_radiometrics.isnull().any()].tolist()\n",
    "\n",
    "# Drop columns with NaN values\n",
    "sm_radiometrics = sm_radiometrics.drop(columns=columns_with_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bacbd02-7564-4d21-b480-ad893aa87977",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos y selección de características\n",
    "\n",
    "Se sigue la metodología realizada por Hector Henriquez en el trabajo [EGFR mutation prediction using F18-FDG PET-CT based radiomics features in non-small cell lung cancer](https://arxiv.org/pdf/2303.08569.pdf) para evaluar el rendimiento de modelos en las caracterterísticas radiométricas.\n",
    "\n",
    "Algunas configuraciones importantes:\n",
    "- Se entrena con un modelo RandomForestClassifier.\n",
    "- Se entrena y evalúa el rendimiento para KFold con $k=3$.\n",
    "- Se obtienen los resultados en las métricas *accuracy*, *AUC*, *Precision*, *Recall*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "801c11a7-19fc-4843-8c98-02a2167e6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    \n",
    "    # Predicted probabilities for class 1 (positive class) for AUC calculation\n",
    "    probas = model.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, probas)\n",
    "    \n",
    "    # Confusion matrix for true positives and false positives\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    true_positives = cm[1, 1]\n",
    "    false_positives = cm[0, 1]\n",
    "    \n",
    "    # Calculate precision, recall, and avoid division by zero\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
    "    recall = true_positives / (true_positives + cm[1, 0]) if (true_positives + cm[1, 0]) != 0 else 0\n",
    "    \n",
    "    return accuracy, auc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d1aca-dcfd-4ed5-aeaf-f95d78aa3d97",
   "metadata": {},
   "source": [
    "### I. Transformación y filtro de datos\n",
    "- Se filtran las características de acuerdo a *Low Variance Filter*.\n",
    "- Se filtran las características con **Selección Univariada de características** con *p-value>0.05*.\n",
    "- Se estandarizan las variables al intervalo $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a2bad7ce-c9e5-455c-acc3-abf9edca804b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 24)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = sm_radiometrics.drop(columns=['EGFR'])\n",
    "y = sm_radiometrics['EGFR']\n",
    "\n",
    "# Step 1: Remove features with low variance\n",
    "variance_threshold = 0.01  # You can adjust this threshold as needed\n",
    "selector = VarianceThreshold(threshold=variance_threshold)\n",
    "X_high_variance = selector.fit_transform(X)\n",
    "\n",
    "# Convert X_high_variance to a DataFrame with the selected features\n",
    "X_high_variance = pd.DataFrame(X_high_variance, columns=X.columns[selector.get_support()])\n",
    "\n",
    "# Step 2: Univariate feature selection - SelectPercentile - Filter features with p-value less than 0.05\n",
    "p_value_threshold = 0.05\n",
    "\n",
    "percentile_selector = SelectPercentile(f_regression, percentile=100)  # You can adjust the percentile\n",
    "X_percentile = percentile_selector.fit_transform(X_high_variance, y)\n",
    "significant_percentile_features = X_high_variance.columns[percentile_selector.pvalues_ < p_value_threshold]\n",
    "X_filtered_percentile = X_high_variance[significant_percentile_features]\n",
    "\n",
    "# Step 3: Scale the features to be non-negative and keep the original column names\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X_filtered_percentile), columns=X_filtered_percentile.columns)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440063a1-b0b5-4bd9-9221-bb05f42f3317",
   "metadata": {},
   "source": [
    "### II. Búsqueda de los mejores hiperparámetros del modelo con Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc7b777d-5cab-4668-8754-65e8ee70b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "#X = sm_radiometrics.drop(columns=['EGFR'])\n",
    "#y = sm_radiometrics['EGFR']\n",
    "\n",
    "# gridsearch\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "    'criterion': [\"gini\", \"entropy\"],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50, 100],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_split': [2, 5, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 2, 4, 10, 20],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rf_model, param_grid)\n",
    "clf.fit(X, y)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "best_params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50a28e8f-357c-4667-a5b4-68040199fbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e208a-2a6c-4f69-a973-74d3abb17ac9",
   "metadata": {},
   "source": [
    "### III. Evaluación inicial del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "725da9d9-17a9-4dde-b4dc-69c6261007fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds for cross-validation\n",
    "k_folds = 3\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c312037d-7eb2-468d-aeb6-5ec5bb9757fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m training_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(X):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Train a RandomForestClassifier\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     rf_model \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], X\u001b[38;5;241m.\u001b[39miloc[test_index], y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     12\u001b[0m     rf_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'learning_rate'"
     ]
    }
   ],
   "source": [
    "# Initial model performance\n",
    "initial_results = []\n",
    "training_results = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Train a RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    training_results.append(evaluate_model(rf_model, X_train, y_train))\n",
    "    initial_results.append(evaluate_model(rf_model, X_test, y_test))\n",
    "\n",
    "\n",
    "# Calculate mean results for training and testing\n",
    "training_average_results = np.mean(training_results, axis=0)\n",
    "initial_average_results = np.mean(initial_results, axis=0)\n",
    "\n",
    "# Print mean training results\n",
    "print(\"Mean Training Results:\")\n",
    "print(f\"Accuracy: {training_average_results[0]}\")\n",
    "print(f\"AUC: {training_average_results[1]}\")\n",
    "print(f\"Precision: {training_average_results[2]}\")\n",
    "print(f\"Recall: {training_average_results[3]}\")\n",
    "\n",
    "# Print mean testing results\n",
    "print(\"\\nMean Testing Results:\")\n",
    "print(f\"Accuracy: {initial_average_results[0]}\")\n",
    "print(f\"AUC: {initial_average_results[1]}\")\n",
    "print(f\"Precision: {initial_average_results[2]}\")\n",
    "print(f\"Recall: {initial_average_results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf2706-bfb5-4302-82d4-bf8a04032f4d",
   "metadata": {},
   "source": [
    "### IV. Selección de características con *backward selection*\n",
    "Se filtran las características menos relevantes de acuerdo al proceso de *backward selection* usando el modelo *RandomForestClassifier* con KFold con *k=5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca4703e5-ebd5-427b-8521-741fec316fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed feature body_wavelet-HHL_glrlm_LongRunEmphasis, Current results: [0.71464646 0.78888889 0.75       0.43333333]\n",
      "Stopping criterion reached. No significant improvement.\n",
      "Final selected features: ['body_log-sigma-3-mm-3D_glszm_SmallAreaEmphasis', 'body_log-sigma-3-mm-3D_glszm_SmallAreaHighGrayLevelEmphasis', 'body_wavelet-HHH_glszm_SmallAreaEmphasis', 'body_wavelet-HHH_glszm_SmallAreaLowGrayLevelEmphasis', 'body_wavelet-HHL_gldm_LargeDependenceEmphasis', 'body_wavelet-HHL_gldm_LargeDependenceHighGrayLevelEmphasis', 'body_wavelet-HHL_gldm_LargeDependenceLowGrayLevelEmphasis', 'body_wavelet-HHL_glrlm_LongRunHighGrayLevelEmphasis', 'body_wavelet-HHL_glrlm_LongRunLowGrayLevelEmphasis', 'body_wavelet-HHL_glrlm_RunVariance', 'body_wavelet-HHL_glszm_SmallAreaEmphasis', 'body_wavelet-HHL_glszm_SmallAreaHighGrayLevelEmphasis', 'body_wavelet-HLL_glszm_GrayLevelNonUniformityNormalized', 'body_wavelet-HLL_glszm_HighGrayLevelZoneEmphasis', 'body_wavelet-HLL_glszm_LowGrayLevelZoneEmphasis', 'body_wavelet-LHH_glszm_SizeZoneNonUniformity', 'body_wavelet-LHH_glszm_SmallAreaEmphasis', 'body_wavelet-LHH_glszm_SmallAreaLowGrayLevelEmphasis', 'body_wavelet-LHL_ngtdm_Busyness', 'body_wavelet-LLH_firstorder_Range', 'body_wavelet-LLL_glszm_LargeAreaHighGrayLevelEmphasis', 'body_wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis', 'body_wavelet-LLL_glszm_ZoneVariance']\n"
     ]
    }
   ],
   "source": [
    "## Backward feature selection with k-fold cross-validation\n",
    "selected_features = list(X.columns)\n",
    "\n",
    "prev_accuracy = np.inf  # Initialize with a high value\n",
    "tolerance = 1e-1  # Define a tolerance for stopping criterion\n",
    "\n",
    "for _ in range(len(selected_features) - 1):\n",
    "    # Store current performance\n",
    "    best_accuracy = 0\n",
    "    best_results = None\n",
    "    feature_to_remove = None\n",
    "\n",
    "    # Try removing each feature and evaluate the model using k-fold cross-validation\n",
    "    for feature in selected_features:\n",
    "        current_features = [f for f in selected_features if f != feature]\n",
    "        accuracy_per_fold = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[current_features].iloc[train_index], X[current_features].iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            rf_model = RandomForestClassifier(random_state=42)\n",
    "            rf_model.fit(X_train, y_train)\n",
    "            accuracy_per_fold.append(evaluate_model(rf_model, X_test, y_test))\n",
    "\n",
    "        # Update best feature to remove\n",
    "        if np.mean(accuracy_per_fold, axis=0)[0] > best_accuracy:\n",
    "            best_accuracy = np.mean(accuracy_per_fold, axis=0)[0]\n",
    "            best_results = np.mean(accuracy_per_fold, axis=0)\n",
    "            feature_to_remove = feature\n",
    "\n",
    "    # Stop if the change in accuracy is below the tolerance\n",
    "    if prev_accuracy - best_accuracy < tolerance:\n",
    "        print(\"Stopping criterion reached. No significant improvement.\")\n",
    "        break\n",
    "\n",
    "    prev_accuracy = best_accuracy\n",
    "\n",
    "    # Remove the least important feature\n",
    "    selected_features.remove(feature_to_remove)\n",
    "    print(f\"Removed feature {feature_to_remove}, Current results: {best_results}\")\n",
    "\n",
    "# Final selected features\n",
    "print(\"Final selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dba62f-328d-4e11-9249-6eaf9ca8e0d0",
   "metadata": {},
   "source": [
    "## Version 2: Multidimensional Feature Selection\n",
    "Se seleccionan las características mas relevantes usando *mfds*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d39367a6-c4f9-4de1-a828-f84b74772f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SEXO_MASCULINO', 'EDAD', 'body_diagnostics_Image-interpolated_Maximum',\n",
      "       'body_diagnostics_Image-interpolated_Mean',\n",
      "       'body_diagnostics_Image-interpolated_Minimum',\n",
      "       'body_diagnostics_Image-original_Maximum',\n",
      "       'body_diagnostics_Image-original_Mean',\n",
      "       'body_diagnostics_Mask-interpolated_Maximum',\n",
      "       'body_diagnostics_Mask-interpolated_Mean',\n",
      "       'body_diagnostics_Mask-interpolated_Minimum',\n",
      "       ...\n",
      "       'body_wavelet-LLL_glszm_ZonePercentage',\n",
      "       'body_wavelet-LLL_glszm_ZoneVariance',\n",
      "       'body_wavelet-LLL_ngtdm_Busyness', 'body_wavelet-LLL_ngtdm_Coarseness',\n",
      "       'body_wavelet-LLL_ngtdm_Complexity', 'body_wavelet-LLL_ngtdm_Contrast',\n",
      "       'body_wavelet-LLL_ngtdm_Strength',\n",
      "       'body_diagnostics_Mask-original_CenterOfMass_x',\n",
      "       'body_diagnostics_Mask-original_CenterOfMass_y',\n",
      "       'body_diagnostics_Mask-original_CenterOfMass_z'],\n",
      "      dtype='object', length=1304)\n"
     ]
    }
   ],
   "source": [
    "import mdfs\n",
    "\n",
    "# Separate features and target\n",
    "X = sm_radiometrics.drop(columns=['EGFR']).to_numpy()\n",
    "y = sm_radiometrics['EGFR'].astype(np.intc).to_numpy()\n",
    "\n",
    "result = mdfs.run(X, y, seed=0, n_contrast=10, dimensions=2, divisions=1, discretizations=1,\n",
    "        range_=None, pc_xi=0.25, p_adjust_method='fdr_tsbh', level=0.3)\n",
    "\n",
    "relevant_var = result['relevant_variables']\n",
    "\n",
    "# Get the names of relevant variables from the original DataFrame\n",
    "original_column_names = sm_radiometrics.drop(columns=['EGFR']).columns\n",
    "relevant_column_names = original_column_names[relevant_var]\n",
    "\n",
    "print(relevant_column_names)\n",
    "\n",
    "# Create a new DataFrame with the relevant variables and original column names\n",
    "X = pd.DataFrame(X[:, relevant_var], columns=relevant_column_names)\n",
    "y = sm_radiometrics['EGFR']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f12c464-d52d-46c6-98b3-e28cdfba3af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Results:\n",
      "Accuracy: 0.6262626262626263\n",
      "AUC: 0.5341269841269841\n",
      "Precision: 0.1111111111111111\n",
      "Recall: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Number of folds for cross-validation\n",
    "k_folds = 3\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=4)\n",
    "\n",
    "# Initial model performance\n",
    "initial_results = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Train a RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    initial_results.append(evaluate_model(rf_model, X_test, y_test))\n",
    "\n",
    "# Print initial results\n",
    "initial_average_results = np.mean(initial_results, axis=0)\n",
    "\n",
    "print(\"Initial Results:\")\n",
    "print(f\"Accuracy: {initial_average_results[0]}\")\n",
    "print(f\"AUC: {initial_average_results[1]}\")\n",
    "print(f\"Precision: {initial_average_results[2]}\")\n",
    "print(f\"Recall: {initial_average_results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66152817-f740-46a4-a8d7-2208273b6ae2",
   "metadata": {},
   "source": [
    "### Preguntas\n",
    "- Revisar el procesamiento y aplicación del excel (filtros, normalización y otros) para la configuración del extractor - comparar con el paper de Hector.\n",
    "- Consultar si las imágenes PET de los resultados del paper se realiza la normalización con el PET de liver.\n",
    "- Se tienen que filtrar las columnas de torax3d porque para algunos pacientes no está aquella información.\n",
    "\n",
    "### Falta\n",
    "- Implementar para todos los filtros posibles.\n",
    "- Normalizar imágenes PET (creo).\n",
    "- hyperparameter search was performed with gridsearch and the performance metrics were\n",
    "calculated with 100 repetitions of 5-fold cross-validation.\n",
    "- Implementar lo anterior para que sea entrenado y validado en Stanford, para luego testear en Santa María."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f63f5e-90f1-4bea-a59e-75f74c1ccedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a38507-8708-49e7-aa20-d196e9597173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
