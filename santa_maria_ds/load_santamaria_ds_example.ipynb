{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b1781ab-b7ae-4336-acf3-e5d240560067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import resource\n",
    "import tensorflow_datasets as tfds\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "242b7718-d456-4e40-84c4-04998c7e926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the santa maria dataset, specifically the torax3d_1 partition. If you want to get another partition\n",
    "# replace with 'pet_01' or 'body_01'\n",
    "sample_dataset, info = tfds.load('santa_maria_dataset/torax3d_1', with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f05bb932-a88d-4345-a2c8-c2705ea49ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_testing_sm_datasets(split_val=0.8, random_seed):\n",
    "    '''Creates random training and testing balanced partitions given the split_val. \n",
    "    Returns two datasets, one training and other for testing.'''\n",
    "    \n",
    "    # Define the positive and negative patients\n",
    "    pos_patients = [f'sm_{str(i).zfill(3)}' for i in range(1, 13)]\n",
    "    neg_patients = [f'sm_{str(i).zfill(3)}' for i in range(13, 36)]\n",
    "    \n",
    "    # Get the split keys (splits) of the dataset\n",
    "    split_keys = list(info.splits.keys())\n",
    "    \n",
    "    # Find positive and negative patients that are also in the split keys\n",
    "    pos_patients = [patient for patient in pos_patients if patient in split_keys]\n",
    "    neg_patients = [patient for patient in neg_patients if patient in split_keys]\n",
    "    \n",
    "    # Shuffle the order of positive and negative patients for randomness\n",
    "    random.shuffle(pos_patients, random_seed)\n",
    "    random.shuffle(neg_patients, random_seed)\n",
    "    \n",
    "    # Calculate the number of patients for training and testing\n",
    "    train_pos_count = int(split_val * len(pos_patients))\n",
    "    train_neg_count = int(split_val * len(neg_patients))\n",
    "    \n",
    "    # Create the training and testing sets\n",
    "    training_patients = pos_patients[:train_pos_count] + neg_patients[:train_neg_count]\n",
    "    testing_patients = pos_patients[train_pos_count:] + neg_patients[train_neg_count:]\n",
    "    \n",
    "    # Create dictionaries to hold the training and testing data\n",
    "    training_data = {patient: sample_dataset[patient] for patient in training_patients}\n",
    "    testing_data = {patient: sample_dataset[patient] for patient in testing_patients}\n",
    "    \n",
    "    \n",
    "    # Create a generator for the training dataset\n",
    "    def generate_training_data():\n",
    "        for patient_id in training_patients:\n",
    "            patient_data = training_data[patient_id]\n",
    "            for data in patient_data:\n",
    "                yield data['patient_id'], data['img_exam'], data['mask_exam'], data['label']\n",
    "    \n",
    "    # Create a TensorFlow Dataset from the generator\n",
    "    training_dataset = tf.data.Dataset.from_generator(\n",
    "        generate_training_data,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),  # For patient_id\n",
    "            tf.TensorSpec(shape=(None, None, None), dtype=tf.uint16),  # For img_exam\n",
    "            tf.TensorSpec(shape=(None, None, None), dtype=tf.uint16),  # For mask_exam\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int64)  # For label\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create a generator for the training dataset\n",
    "    def generate_testing_data():\n",
    "        for patient_id in testing_patients:\n",
    "            patient_data = testing_data[patient_id]\n",
    "            print(patient_data.keys())\n",
    "            for data in patient_data:\n",
    "                yield data['patient_id'], data['img_exam'], data['mask_exam'], data['label']\n",
    "    \n",
    "    # Create a TensorFlow Dataset from the generator\n",
    "    testing_dataset = tf.data.Dataset.from_generator(\n",
    "        generate_testing_data,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),  # For patient_id\n",
    "            tf.TensorSpec(shape=(None, None, None), dtype=tf.uint16),  # For img_exam\n",
    "            tf.TensorSpec(shape=(None, None, None), dtype=tf.uint16),  # For mask_exam\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int64)  # For label\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return training_dataset, testing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cec59a7a-a3de-41c8-8f1e-40cee78b2275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 12:55:30.449864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n",
      "Patient ID: sm_010\n",
      "Image Exam Shape: (512, 512, 1)\n",
      "Mask Exam Shape: (512, 512, 1)\n",
      "Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 12:55:30.761068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-10-17 12:55:30.833064: W tensorflow/core/framework/op_kernel.cc:1818] UNKNOWN: AttributeError: '_PrefetchDataset' object has no attribute 'keys'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/tmp/ipykernel_448783/739863865.py\", line 55, in generate_testing_data\n",
      "    print(patient_data.keys())\n",
      "\n",
      "AttributeError: '_PrefetchDataset' object has no attribute 'keys'\n",
      "\n",
      "\n",
      "2023-10-17 12:55:30.833230: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: AttributeError: '_PrefetchDataset' object has no attribute 'keys'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/tmp/ipykernel_448783/739863865.py\", line 55, in generate_testing_data\n",
      "    print(patient_data.keys())\n",
      "\n",
      "AttributeError: '_PrefetchDataset' object has no attribute 'keys'\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} AttributeError: '_PrefetchDataset' object has no attribute 'keys'\nTraceback (most recent call last):\n\n  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_448783/739863865.py\", line 55, in generate_testing_data\n    print(patient_data.keys())\n\nAttributeError: '_PrefetchDataset' object has no attribute 'keys'\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Iterate through the testing dataset\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patient_id, img_exam, mask_exam, label \u001b[38;5;129;01min\u001b[39;00m testing_ds:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m, patient_id\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage Exam Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_exam\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:797\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    796\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 780\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3018\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_4_device_/job:localhost/replica:0/task:0/device:CPU:0}} AttributeError: '_PrefetchDataset' object has no attribute 'keys'\nTraceback (most recent call last):\n\n  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/kali/miniconda3/envs/lung_radiomics_2/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_448783/739863865.py\", line 55, in generate_testing_data\n    print(patient_data.keys())\n\nAttributeError: '_PrefetchDataset' object has no attribute 'keys'\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "training_ds, testing_ds = get_training_testing_sm_datasets()\n",
    "\n",
    "training_stop = 0\n",
    "testing_stop = 0\n",
    "# Iterate through the training dataset\n",
    "for patient_id, img_exam, mask_exam, label in training_ds:\n",
    "    training_stop +=1\n",
    "    print(\"Patient ID:\", patient_id.numpy().decode('utf-8'))\n",
    "    print(\"Image Exam Shape:\", img_exam.shape)\n",
    "    print(\"Mask Exam Shape:\", mask_exam.shape)\n",
    "    print(\"Label:\", label.numpy())\n",
    "\n",
    "    if training_stop == 10:\n",
    "        break\n",
    "\n",
    "# Iterate through the testing dataset\n",
    "for patient_id, img_exam, mask_exam, label in testing_ds:\n",
    "    print(\"Patient ID:\", patient_id.numpy().decode('utf-8'))\n",
    "    print(\"Image Exam Shape:\", img_exam.shape)\n",
    "    print(\"Mask Exam Shape:\", mask_exam.shape)\n",
    "    print(\"Label:\", label.numpy())\n",
    "    testing_stop += 1\n",
    "    if testing_stop == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8d8cb-9550-4237-9f2f-7d4266f913ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
