{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJJUhtzk0GyZ",
    "outputId": "d633071e-cb06-44b0-aca2-6e4cfba6b7da"
   },
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGlTmEYzxi7Y"
   },
   "source": [
    "\n",
    "\n",
    "# Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbNdxvB7IAMS",
    "outputId": "82434382-98f3-4d8e-a0e4-3acb513d0919"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install pynrrd\n",
    "#!{sys.executable} -m pip install tensorflow\n",
    "#!{sys.executable} -m pip install opencv-python\n",
    "#!{sys.executable} -m pip install pandas\n",
    "#!{sys.executable} -m pip install matplotlib\n",
    "#!{sys.executable} -m pip install tdqm\n",
    "#!{sys.executable} -m pip install scikit-image\n",
    "#!{sys.executable} -m pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvaAIbYKIAMT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nrrd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcdZxHmbIAMU"
   },
   "outputs": [],
   "source": [
    "def show_slice_window(slice, level, window):\n",
    "\n",
    "    \"\"\"\n",
    "    Permite ajustar nivel y ancho de ventana para mejorar contraste de la imagen.\n",
    "    input: imagen np.array 2D.\n",
    "    output: imagen np.array 2D ajustada.\n",
    "   \"\"\"\n",
    "    max = level + window/2\n",
    "    min = level - window/2\n",
    "    slice = slice.clip(min,max)\n",
    "    return(slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkuZNn5xIAMU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def visualizeImgMask(img, mask, index, pet):\n",
    "\n",
    "    \"\"\"\n",
    "  Función para visualizar las imágenes, máscaras y fusión.\n",
    "  INPUT: imágenes y máscaras como numpy array 3D (numero de imagenes, alto, ancho),\n",
    "  index corresponde al número de la imágen a visualizar.\n",
    "  PET: True or False. Si es True se visualiza en inverso (cmap=gray_r),\n",
    "  sólo por un tema de convención de la visualización del PET.\n",
    "    \"\"\"\n",
    "\n",
    "    if(pet == 1):\n",
    "        f = plt.figure(figsize=(10,10), frameon=True)\n",
    "        f.add_subplot(1, 3, 1)\n",
    "        plt.title(\"PET\")\n",
    "        plt.imshow(cv2.rotate(img[index,:,:],cv2.ROTATE_90_CLOCKWISE), cmap='gray_r')\n",
    "        f.add_subplot(1, 3, 2)\n",
    "        plt.title(\"Mask\")\n",
    "        plt.imshow(cv2.rotate(mask[index,:,:],cv2.ROTATE_90_CLOCKWISE), cmap='Blues')\n",
    "        f.add_subplot(1, 3, 3)\n",
    "        plt.title(\"Fusion\")\n",
    "        plt.imshow(cv2.rotate(img[index,:,:],cv2.ROTATE_90_CLOCKWISE), cmap='gray_r')\n",
    "        plt.imshow(cv2.rotate(mask[index,:,:],cv2.ROTATE_90_CLOCKWISE), cmap='gnuplot', alpha= 0.6)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        f = plt.figure(figsize=(10,10), frameon=True)\n",
    "        f.add_subplot(1, 3, 1)\n",
    "        plt.title(\"CT\")\n",
    "        plt.imshow(cv2.rotate(img[index,:,:],cv2.ROTATE_90_CLOCKWISE), cmap='gray')\n",
    "        f.add_subplot(1, 3, 2)\n",
    "        plt.title(\"Mask\")\n",
    "        plt.imshow(cv2.rotate(mask[index,:,:],cv2.ROTATE_90_CLOCKWISE), cmap='Blues')\n",
    "        f.add_subplot(1, 3, 3)\n",
    "        plt.title(\"Fusion\")\n",
    "        plt.imshow(cv2.rotate(img[index,:,:],cv2.ROTATE_90_CLOCKWISE), cmap='gray')\n",
    "        plt.imshow(cv2.rotate(mask[index,:,:],cv2.ROTATE_90_CLOCKWISE), cmap='gnuplot', alpha= 0.6)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzR1qdvLIAMU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extractImages(data_img, data_mask):\n",
    "\n",
    "    \"\"\"\n",
    "  Función que extrae sólo las imágenes de los niveles que contienen segmentación.\n",
    "  INPUT: volumen de imágenes y máscaras numpy array 3D (numero de imagen, alto, ancho), directo de la\n",
    "  carga del archivo .nrrd.\n",
    "  Busca las máscaras con segmentaciones y extrae los cortes de estos niveles.\n",
    "  OUTPUT: devuelve np.array 3D con las imágenes y máscaras sólo de los niveles del tumor.\n",
    "    \"\"\"\n",
    "\n",
    "    images = []\n",
    "    masks = []\n",
    "    positive_slices = []\n",
    "\n",
    "    for i in trange(data_img.shape[2]):\n",
    "        segmentation = data_mask[:,:,i]\n",
    "        if (np.sum(segmentation)>0):\n",
    "            positive_slices.append(i)\n",
    "\n",
    "        ## Extrae las imágenes sólo con segmentación - tumor\n",
    "    for axial in positive_slices:\n",
    "        segment = data_mask[:,:,axial]\n",
    "        ct = data_img[:,:,axial]\n",
    "        images.append(ct)\n",
    "        masks.append(segment)\n",
    "\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "    return(images, masks)\n",
    "\n",
    "\n",
    "def roiExtraction (img,mask,margin):\n",
    "    \"\"\"\n",
    "  Función para extraer el ROI donde se encuentra el tumor en una imagen.\n",
    "  INPUT: imagen y máscaras numpy array 2D.\n",
    "  margin: corresponde al número de pixeles como margen por fuera de los pixeles de la máscara.\n",
    "  OUTPUT: Devuelve el ROI.\n",
    "  \"\"\"\n",
    "\n",
    "    roi_extract = []\n",
    "\n",
    "    for i in range(mask.shape[0]):\n",
    "        img_instance = img[i].copy()\n",
    "        mask_instance = mask[i].copy()\n",
    "        index = np.where(mask_instance)\n",
    "        roi = img_instance[np.unique(index[0])[0]-margin:np.unique(index[0])[-1]+margin, np.unique(index[1])[0]-margin: np.unique(index[1])[-1]+margin]\n",
    "        roi_extract.append(roi)\n",
    "\n",
    "    roi_extract = np.array(roi_extract, dtype='object')\n",
    "    return(roi_extract)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHs SM (pet, body, torax3d)\n",
    "\n",
    "#model_name = \"pet\"\n",
    "model_name = \"body\"\n",
    "#model_name = \"torax3d\"\n",
    "\n",
    "path_img_n = f'NRRD/EGFR-/{model_name}/image'\n",
    "path_mask_n = f'NRRD/EGFR-/{model_name}/label'\n",
    "############################################\n",
    "path_img_p = f'NRRD/EGFR+/{model_name}/image'\n",
    "path_mask_p = f'NRRD/EGFR+/{model_name}/label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHs ST (pet, body, torax3d)\n",
    "\n",
    "#model_name = \"pet\"\n",
    "#model_name = \"ct\"\n",
    "#model_name = \"chest_ct\"\n",
    "#\n",
    "#path_img_n = f'NNRD-ST/data/AMCEGFR-/image/{model_name}'\n",
    "#path_mask_n = f'NNRD-ST/data/AMCEGFR-/label/{model_name}'\n",
    "#\n",
    "#############################################\n",
    "#\n",
    "#path_img_p = f'NNRD-ST/data/AMCEGFR+/image/{model_name}'\n",
    "#path_mask_p = f'NNRD-ST/data/AMCEGFR+/label/{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_list_n = []\n",
    "\n",
    "for i in range (len(os.listdir(path_img_n))):\n",
    "    if (os.listdir(path_img_n)[i][-5:] == '.nrrd'):\n",
    "        patient_list_n.append(os.listdir(path_img_n)[i])\n",
    "print(patient_list_n)\n",
    "\n",
    "labels_n =[0 for _ in range(len(patient_list_n))]\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "patient_list_p = []\n",
    "\n",
    "for i in range (len(os.listdir(path_img_p))):\n",
    "    if (os.listdir(path_img_p)[i][-5:] == '.nrrd'):\n",
    "        patient_list_p.append(os.listdir(path_img_p)[i])\n",
    "print(patient_list_p)\n",
    "\n",
    "labels_p = [1 for _ in range(len(patient_list_p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(patient_list_n, labels_n, test_size=0.1, random_state=42)\n",
    "#X_train_n, X_val_n, y_train_n, y_val_n = train_test_split(X_train_v_n, y_train_v_n, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(patient_list_p, labels_p, test_size=0.1, random_state=42)\n",
    "#X_train_p, X_val_p, y_train_p, y_val_p = train_test_split(patient_list_p, labels_p, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_f = X_train_n + X_train_p\n",
    "y_train_f = y_train_n + y_train_p\n",
    "\n",
    "#X_val_f = X_val_n + X_val_p\n",
    "#y_val_f = y_val_n + y_val_p\n",
    "\n",
    "X_test_f = X_test_n + X_test_p\n",
    "y_test_f = y_test_n + y_test_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Lectura de los archivos nrrd con sus máscaras, generación de imágenes y obtención del roi (region of interest)\n",
    "\n",
    "margin = 4\n",
    "\n",
    "def data_gen(patient_list, labels, model, margin = 4):\n",
    "    data_list = []\n",
    "    data_label = []\n",
    "    patient_id = [s[:6] for s in patient_list]    \n",
    "    path_img = ''\n",
    "    path_mask = ''\n",
    "\n",
    "    for id, label in zip(patient_id, labels):\n",
    "        if label:\n",
    "            path_img = path_img_p\n",
    "            path_mask = path_mask_p     \n",
    "        else:\n",
    "            path_img = path_img_n\n",
    "            path_mask = path_mask_n\n",
    "\n",
    "        data_tumour,_ = nrrd.read( f'{path_img}/{id}_{model}_image.nrrd')\n",
    "        mask_tumour,_ = nrrd.read(f'{path_mask}/{id}_{model}_segmentation.nrrd')\n",
    "        img_tumour, mask_tumour = extractImages(data_tumour, mask_tumour)\n",
    "        roi_tumour = roiExtraction(img_tumour, mask_tumour, margin)\n",
    "        for slice in range(len(roi_tumour)):\n",
    "                data_label.append(label)\n",
    "                data_list.append(roi_tumour[slice])    \n",
    "    return data_list, data_label\n",
    "\n",
    "X_train, y_train = data_gen(X_train_f, y_train_f, model_name)\n",
    "#X_val, y_val = data_gen(X_val_f, y_val_f, model_name)\n",
    "X_test, y_test = data_gen(X_test_f, y_test_f, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def resize_data(df):\n",
    "\n",
    "    target_input_shape = (32, 32, 1) \n",
    "\n",
    "    resized_images = []\n",
    "\n",
    "    for image in df:\n",
    "        resized_image = resize(image, target_input_shape, mode='reflect')\n",
    "        resized_images.append(resized_image)\n",
    "\n",
    "    data_resized = np.asarray(resized_images).astype(np.float32)\n",
    "\n",
    "    data_resized = tf.convert_to_tensor(data_resized, dtype=tf.float32)\n",
    "\n",
    "    return data_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resized = resize_data(X_train)\n",
    "#X_val_resized = resize_data(X_val)\n",
    "X_test_resized = resize_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_resized.shape)\n",
    "#print(X_val_resized.shape)\n",
    "print(X_test_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "#y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFMBG4cqxTfv"
   },
   "source": [
    "# CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4i1_J3QxTOs"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "def create_cnn(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    ### Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.Activation('relu')) \n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    #tf.keras.regularizers.L2(0.01) en todas las capas\n",
    "    #tf.keras.optimizers.AdamW()\n",
    "    #tf.keras.optimizers.schedules.CosineDecay(\n",
    "    #\n",
    "    model.add(layers.Conv2D(64, (3, 3)))\n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.Activation('relu')) \n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3)))\n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.Activation('relu')) \n",
    "\n",
    "    ### Fully connected layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64))   \n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.Activation('relu'))  \n",
    "\n",
    "    ### Output Layer with Sigmoid activation for binary cross-entropy\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    ### Compile the model with binary cross-entropy loss function\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# input dimensions\n",
    "input_shape = (32, 32, 1)\n",
    "\n",
    "\n",
    "model = create_cnn(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32  \n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_resized, \n",
    "    y_train, \n",
    "    epochs=num_epochs, \n",
    "    steps_per_epoch=len(X_train_resized) // batch_size, \n",
    "    validation_data=(X_test_resized, y_test),\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_resized, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p saved_model\n",
    "#model.save('saved_model/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title(f'Training and validation accuracy - for {model_name}')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'results/{model_name}-acc.png')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title(f'Training and validation loss - for {model_name}')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'results/{model_name}-loss.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
