{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7a7a00-6fe2-4196-b1f7-1994012b8b2d",
   "metadata": {},
   "source": [
    "# Análisis de características Radiométricas de Stanford\n",
    "\n",
    "Se procesan las características radiométricas y se experimentan para obtener el resultado en modelos\n",
    "**Roberto Araya**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c398e3d6-6426-4e73-88f8-1efa3c6763c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2, VarianceThreshold, SelectPercentile, f_regression\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27844f78-7495-4c39-b150-e2c8377f876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameteres\n",
    "binwidth = 10\n",
    "sigma = [1,2,3]\n",
    "normalize= True\n",
    "imageTypes = ['Original', 'LoG', 'Square', 'SquareRoot']\n",
    "\n",
    "\n",
    "sm_radiometrics_file=f'stanford_data_info_all__binwidth_{binwidth}_sigma_[1, 2, 3]_changed.csv'\n",
    "sm_radiometrics = pd.read_csv(sm_radiometrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2899120-8f97-47cf-824b-e7d8bec3f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGFR mutation status\n",
      "Wildtype         126\n",
      "Mutant            43\n",
      "Unknown           33\n",
      "Not collected      5\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Patient affiliation</th>\n",
       "      <th>Age at Histological Diagnosis</th>\n",
       "      <th>Weight (lbs)</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Smoking status</th>\n",
       "      <th>Pack Years</th>\n",
       "      <th>Quit Smoking Year</th>\n",
       "      <th>%GG</th>\n",
       "      <th>...</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_ZoneEntropy</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_ZonePercentage</th>\n",
       "      <th>torax3d_wavelet-LLL_glszm_ZoneVariance</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Busyness</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Coarseness</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Complexity</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Contrast</th>\n",
       "      <th>torax3d_wavelet-LLL_ngtdm_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMC-001</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>34</td>\n",
       "      <td>Not Collected</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Recorded In Database</td>\n",
       "      <td>Nonsmoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Assessed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMC-002</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>33</td>\n",
       "      <td>Not Collected</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Recorded In Database</td>\n",
       "      <td>Nonsmoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Assessed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMC-003</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>69</td>\n",
       "      <td>Not Collected</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Recorded In Database</td>\n",
       "      <td>Nonsmoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Assessed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMC-004</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>80</td>\n",
       "      <td>Not Collected</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Recorded In Database</td>\n",
       "      <td>Nonsmoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Assessed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMC-005</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>76</td>\n",
       "      <td>Not Collected</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Recorded In Database</td>\n",
       "      <td>Former</td>\n",
       "      <td>30</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>Not Assessed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Case ID Patient affiliation  Age at Histological Diagnosis   Weight (lbs)  \\\n",
       "0  AMC-001            Stanford                             34  Not Collected   \n",
       "1  AMC-002            Stanford                             33  Not Collected   \n",
       "2  AMC-003            Stanford                             69  Not Collected   \n",
       "3  AMC-004            Stanford                             80  Not Collected   \n",
       "4  AMC-005            Stanford                             76  Not Collected   \n",
       "\n",
       "   Gender                 Ethnicity Smoking status Pack Years  \\\n",
       "0    Male  Not Recorded In Database      Nonsmoker        NaN   \n",
       "1  Female  Not Recorded In Database      Nonsmoker        NaN   \n",
       "2  Female  Not Recorded In Database      Nonsmoker        NaN   \n",
       "3  Female  Not Recorded In Database      Nonsmoker        NaN   \n",
       "4    Male  Not Recorded In Database         Former         30   \n",
       "\n",
       "   Quit Smoking Year           %GG  ...  \\\n",
       "0                NaN  Not Assessed  ...   \n",
       "1                NaN  Not Assessed  ...   \n",
       "2                NaN  Not Assessed  ...   \n",
       "3                NaN  Not Assessed  ...   \n",
       "4             1962.0  Not Assessed  ...   \n",
       "\n",
       "  torax3d_wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis  \\\n",
       "0                                                NaN         \n",
       "1                                                NaN         \n",
       "2                                                NaN         \n",
       "3                                                NaN         \n",
       "4                                                NaN         \n",
       "\n",
       "  torax3d_wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis  \\\n",
       "0                                                NaN        \n",
       "1                                                NaN        \n",
       "2                                                NaN        \n",
       "3                                                NaN        \n",
       "4                                                NaN        \n",
       "\n",
       "  torax3d_wavelet-LLL_glszm_ZoneEntropy  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "\n",
       "  torax3d_wavelet-LLL_glszm_ZonePercentage  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "  torax3d_wavelet-LLL_glszm_ZoneVariance torax3d_wavelet-LLL_ngtdm_Busyness  \\\n",
       "0                                    NaN                                NaN   \n",
       "1                                    NaN                                NaN   \n",
       "2                                    NaN                                NaN   \n",
       "3                                    NaN                                NaN   \n",
       "4                                    NaN                                NaN   \n",
       "\n",
       "  torax3d_wavelet-LLL_ngtdm_Coarseness torax3d_wavelet-LLL_ngtdm_Complexity  \\\n",
       "0                                  NaN                                  NaN   \n",
       "1                                  NaN                                  NaN   \n",
       "2                                  NaN                                  NaN   \n",
       "3                                  NaN                                  NaN   \n",
       "4                                  NaN                                  NaN   \n",
       "\n",
       "  torax3d_wavelet-LLL_ngtdm_Contrast torax3d_wavelet-LLL_ngtdm_Strength  \n",
       "0                                NaN                                NaN  \n",
       "1                                NaN                                NaN  \n",
       "2                                NaN                                NaN  \n",
       "3                                NaN                                NaN  \n",
       "4                                NaN                                NaN  \n",
       "\n",
       "[5 rows x 4665 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sm_radiometrics['EGFR mutation status'].value_counts())\n",
    "sm_radiometrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a6990-4363-4710-839a-45aeeae68ba6",
   "metadata": {},
   "source": [
    "## Procesamiento de datos\n",
    "- Se eliminan columnas no relevantes.\n",
    "- Se vectorizan las características compuestas por categorías de *strings* con el método *one-hot-encoding*.\n",
    "- Se eliminan las columnas que posean alguna fila con valor nulo (INVESIGAR ESTOS CASOS, CASOS SIN EXAMENES TORAX3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63b61e61-3d3c-450e-916b-01edda2c0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "egfr_mutation_status = sm_radiometrics['EGFR mutation status']\n",
    "\n",
    "# Drop columns from 0 to 48\n",
    "sm_radiometrics = sm_radiometrics.drop(sm_radiometrics.columns[0:49], axis=1)\n",
    "#sm_radiometrics = sm_radiometrics.drop(sm_radiometrics.columns[1:2], axis=1)\n",
    "\n",
    "# Add back 'EGFR mutation status' to the DataFrame\n",
    "sm_radiometrics['EGFR mutation status'] = egfr_mutation_status\n",
    "\n",
    "\n",
    "# Define columns related to images\n",
    "columns_to_drop = ['diagnostics_Configuration_EnabledImageTypes', 'diagnostics_Configuration_Settings', \n",
    "                  'diagnostics_Image-original_Dimensionality', 'diagnostics_Mask-original_BoundingBox', \n",
    "                  'diagnostics_Versions_PyRadiomics', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Image-original_Hash', \n",
    "                  'diagnostics_Image-original_Size', 'diagnostics_Image-original_Spacing', 'diagnostics_Mask-original_Hash', \n",
    "                  'diagnostics_Mask-original_Size', 'diagnostics_Mask-original_Spacing', 'diagnostics_Versions_Numpy', \n",
    "                  'diagnostics_Versions_PyWavelet', 'diagnostics_Versions_Python', 'diagnostics_Versions_SimpleITK', \n",
    "                  'diagnostics_Image-interpolated_Size', 'diagnostics_Image-interpolated_Spacing', 'diagnostics_Mask-interpolated_BoundingBox', \n",
    "                  'diagnostics_Mask-interpolated_CenterOfMass', 'diagnostics_Mask-interpolated_CenterOfMassIndex', 'diagnostics_Mask-interpolated_Size',\n",
    "                  'diagnostics_Mask-interpolated_Spacing', 'diagnostics_Mask-original_CenterOfMass']\n",
    "\n",
    "# Define exam types\n",
    "exam_types = ['body_', 'pet_', 'torax3d_']\n",
    "\n",
    "# Generate columns related to images for each exam type\n",
    "columns_to_drop = [exam + s for s in columns_to_drop for exam in exam_types]\n",
    "\n",
    "# Remove specific column from the list\n",
    "columns_to_drop.remove('body_diagnostics_Configuration_EnabledImageTypes')\n",
    "\n",
    "# Drop specified columns while keeping 'EGFR Mutation Status'\n",
    "sm_radiometrics = sm_radiometrics.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "sm_radiometrics['EGFR'] = sm_radiometrics['EGFR mutation status'].replace({'Mutant': 1, 'Wildtype': 0, 'Not collected': 2, 'Unknown': 3})\n",
    "sm_radiometrics = sm_radiometrics.drop(columns=['EGFR mutation status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db398eac-35b8-47e3-811c-0ba34c111179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGFR Counts:\n",
      "EGFR\n",
      "0    126\n",
      "1     43\n",
      "3     33\n",
      "2      5\n",
      "Name: count, dtype: int64\n",
      "Filtered DataFrame:\n",
      "EGFR\n",
      "0    126\n",
      "1     43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "egfr_counts = sm_radiometrics['EGFR'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"EGFR Counts:\")\n",
    "print(egfr_counts)\n",
    "\n",
    "# Filter rows where 'EGFR' is neither 0 nor 1\n",
    "filtered_sm_radiometrics = sm_radiometrics[(sm_radiometrics['EGFR'] == 0) | (sm_radiometrics['EGFR'] == 1)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"Filtered DataFrame:\")\n",
    "print(filtered_sm_radiometrics['EGFR'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55718ca5-8816-4eac-8325-564e2ed83e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['torax3d_diagnostics_Image-interpolated_Maximum',\n",
      "       'torax3d_diagnostics_Image-interpolated_Mean',\n",
      "       'torax3d_diagnostics_Image-interpolated_Minimum',\n",
      "       'torax3d_diagnostics_Image-original_Maximum',\n",
      "       'torax3d_diagnostics_Image-original_Mean',\n",
      "       'torax3d_diagnostics_Image-original_Minimum',\n",
      "       'torax3d_diagnostics_Mask-interpolated_Maximum',\n",
      "       'torax3d_diagnostics_Mask-interpolated_Mean',\n",
      "       'torax3d_diagnostics_Mask-interpolated_Minimum',\n",
      "       'torax3d_diagnostics_Mask-interpolated_VolumeNum',\n",
      "       ...\n",
      "       'torax3d_wavelet-LLL_glszm_SmallAreaHighGrayLevelEmphasis',\n",
      "       'torax3d_wavelet-LLL_glszm_SmallAreaLowGrayLevelEmphasis',\n",
      "       'torax3d_wavelet-LLL_glszm_ZoneEntropy',\n",
      "       'torax3d_wavelet-LLL_glszm_ZonePercentage',\n",
      "       'torax3d_wavelet-LLL_glszm_ZoneVariance',\n",
      "       'torax3d_wavelet-LLL_ngtdm_Busyness',\n",
      "       'torax3d_wavelet-LLL_ngtdm_Coarseness',\n",
      "       'torax3d_wavelet-LLL_ngtdm_Complexity',\n",
      "       'torax3d_wavelet-LLL_ngtdm_Contrast',\n",
      "       'torax3d_wavelet-LLL_ngtdm_Strength'],\n",
      "      dtype='object', length=1515)\n",
      "Filtered DataFrame:\n"
     ]
    }
   ],
   "source": [
    "null_threshold = 0.2\n",
    "\n",
    "# Calculate the percentage of null values in each column\n",
    "null_percentage = filtered_sm_radiometrics.isnull().mean()\n",
    "\n",
    "# Filter columns with null percentage above the threshold\n",
    "columns_to_drop = null_percentage[null_percentage >= null_threshold].index\n",
    "\n",
    "print(columns_to_drop)\n",
    "\n",
    "# Drop the identified columns\n",
    "filtered_sm_radiometrics = filtered_sm_radiometrics.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"Filtered DataFrame:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99155b6b-8a9c-476a-81ba-e3c3b748e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 3031)\n",
      "Filtered DataFrame:\n",
      "(143, 3031)\n"
     ]
    }
   ],
   "source": [
    "row_null_threshold = 10\n",
    "\n",
    "print(filtered_sm_radiometrics.shape)\n",
    "# Count null values in each row\n",
    "null_counts_per_row = filtered_sm_radiometrics.isnull().sum(axis=1)\n",
    "\n",
    "# Filter rows with more than the specified threshold of null values\n",
    "sm_radiometrics = filtered_sm_radiometrics[null_counts_per_row <= row_null_threshold]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"Filtered DataFrame:\")\n",
    "print(sm_radiometrics.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bacbd02-7564-4d21-b480-ad893aa87977",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos y selección de características\n",
    "\n",
    "Se sigue la metodología realizada por Hector Henriquez en el trabajo [EGFR mutation prediction using F18-FDG PET-CT based radiomics features in non-small cell lung cancer](https://arxiv.org/pdf/2303.08569.pdf) para evaluar el rendimiento de modelos en las caracterterísticas radiométricas.\n",
    "\n",
    "Algunas configuraciones importantes:\n",
    "- Se entrena con un modelo RandomForestClassifier.\n",
    "- Se entrena y evalúa el rendimiento para KFold con $k=3$.\n",
    "- Se obtienen los resultados en las métricas *accuracy*, *AUC*, *True Positive Rate*, *False Positive Rate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "801c11a7-19fc-4843-8c98-02a2167e6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    \n",
    "    # Predicted probabilities for class 1 (positive class) for AUC calculation\n",
    "    probas = model.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, probas)\n",
    "    \n",
    "    # Confusion matrix for true positives and false positives\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    true_positives = cm[1, 1]\n",
    "    false_positives = cm[0, 1]\n",
    "    \n",
    "    # Calculate precision, recall, and avoid division by zero\n",
    "    #print('true positives: ', true_positives)\n",
    "    #print('true negatives: ', cm[0,0])\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
    "    recall = true_positives / (true_positives + cm[1, 0]) if (true_positives + cm[1, 0]) != 0 else 0\n",
    "    \n",
    "    return accuracy, auc, precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d1aca-dcfd-4ed5-aeaf-f95d78aa3d97",
   "metadata": {},
   "source": [
    "### I. Transformación y filtro de datos\n",
    "- Se filtran las características de acuerdo a *Low Variance Filter*.\n",
    "- Se filtran las características con **Selección Univariada de características** con *p-value>0.05*.\n",
    "- Se estandarizan las variables al intervalo $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2bad7ce-c9e5-455c-acc3-abf9edca804b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 51)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = sm_radiometrics.drop(columns=['EGFR'])\n",
    "y = sm_radiometrics['EGFR']\n",
    "\n",
    "# Step 1: Remove features with low variance\n",
    "variance_threshold = 0.01  # You can adjust this threshold as needed\n",
    "selector = VarianceThreshold(threshold=variance_threshold)\n",
    "X_high_variance = selector.fit_transform(X)\n",
    "\n",
    "# Convert X_high_variance to a DataFrame with the selected features\n",
    "X_high_variance = pd.DataFrame(X_high_variance, columns=X.columns[selector.get_support()])\n",
    "\n",
    "# Step 2: Univariate feature selection - SelectPercentile - Filter features with p-value less than 0.05\n",
    "p_value_threshold = 0.05\n",
    "\n",
    "percentile_selector = SelectPercentile(f_regression, percentile=100)  # You can adjust the percentile\n",
    "X_percentile = percentile_selector.fit_transform(X_high_variance, y)\n",
    "significant_percentile_features = X_high_variance.columns[percentile_selector.pvalues_ < p_value_threshold]\n",
    "X_filtered_percentile = X_high_variance[significant_percentile_features]\n",
    "\n",
    "# Step 3: Scale the features to be non-negative and keep the original column names\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X_filtered_percentile), columns=X_filtered_percentile.columns)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8829edb-8568-443b-b24d-86aa6d90aa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_logarithm_firstorder_InterquartileRange</th>\n",
       "      <th>body_squareroot_firstorder_InterquartileRange</th>\n",
       "      <th>body_squareroot_firstorder_Range</th>\n",
       "      <th>body_wavelet-HLH_firstorder_Skewness</th>\n",
       "      <th>body_wavelet-HLH_glszm_HighGrayLevelZoneEmphasis</th>\n",
       "      <th>body_wavelet-HLH_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>body_wavelet-HLL_gldm_DependenceEntropy</th>\n",
       "      <th>body_wavelet-LHL_gldm_DependenceEntropy</th>\n",
       "      <th>body_wavelet-LLL_gldm_LargeDependenceHighGrayLevelEmphasis</th>\n",
       "      <th>pet_exponential_firstorder_Minimum</th>\n",
       "      <th>...</th>\n",
       "      <th>pet_wavelet-LLH_firstorder_Maximum</th>\n",
       "      <th>pet_wavelet-LLH_firstorder_Range</th>\n",
       "      <th>pet_wavelet-LLH_glcm_ClusterShade</th>\n",
       "      <th>pet_wavelet-LLH_glcm_ClusterTendency</th>\n",
       "      <th>pet_wavelet-LLH_glcm_JointEnergy</th>\n",
       "      <th>pet_wavelet-LLH_glcm_JointEntropy</th>\n",
       "      <th>pet_wavelet-LLH_glcm_MaximumProbability</th>\n",
       "      <th>pet_wavelet-LLH_glcm_SumEntropy</th>\n",
       "      <th>pet_wavelet-LLH_gldm_LargeDependenceLowGrayLevelEmphasis</th>\n",
       "      <th>pet_wavelet-LLH_glszm_ZoneEntropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014132</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.354126</td>\n",
       "      <td>0.475221</td>\n",
       "      <td>0.479053</td>\n",
       "      <td>0.520947</td>\n",
       "      <td>0.760130</td>\n",
       "      <td>0.746909</td>\n",
       "      <td>0.149618</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233283</td>\n",
       "      <td>0.234292</td>\n",
       "      <td>0.636539</td>\n",
       "      <td>0.966459</td>\n",
       "      <td>0.082246</td>\n",
       "      <td>0.871629</td>\n",
       "      <td>0.134636</td>\n",
       "      <td>0.921615</td>\n",
       "      <td>0.651405</td>\n",
       "      <td>0.929798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020424</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.627934</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.894294</td>\n",
       "      <td>0.907272</td>\n",
       "      <td>0.092708</td>\n",
       "      <td>0.447542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240019</td>\n",
       "      <td>0.281370</td>\n",
       "      <td>0.978057</td>\n",
       "      <td>0.743770</td>\n",
       "      <td>0.327587</td>\n",
       "      <td>0.655821</td>\n",
       "      <td>0.515865</td>\n",
       "      <td>0.705530</td>\n",
       "      <td>0.810247</td>\n",
       "      <td>0.584442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014544</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.123973</td>\n",
       "      <td>0.610127</td>\n",
       "      <td>0.239766</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.727060</td>\n",
       "      <td>0.663205</td>\n",
       "      <td>0.149217</td>\n",
       "      <td>0.558188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181982</td>\n",
       "      <td>0.194694</td>\n",
       "      <td>0.664476</td>\n",
       "      <td>0.889245</td>\n",
       "      <td>0.028861</td>\n",
       "      <td>0.956205</td>\n",
       "      <td>0.121389</td>\n",
       "      <td>0.974795</td>\n",
       "      <td>0.591208</td>\n",
       "      <td>0.639288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307839</td>\n",
       "      <td>0.309810</td>\n",
       "      <td>0.330353</td>\n",
       "      <td>0.670973</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.865872</td>\n",
       "      <td>0.109035</td>\n",
       "      <td>0.538966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063857</td>\n",
       "      <td>0.078791</td>\n",
       "      <td>0.851609</td>\n",
       "      <td>0.844732</td>\n",
       "      <td>0.153114</td>\n",
       "      <td>0.832072</td>\n",
       "      <td>0.326818</td>\n",
       "      <td>0.870278</td>\n",
       "      <td>0.708948</td>\n",
       "      <td>0.571515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086327</td>\n",
       "      <td>0.081392</td>\n",
       "      <td>0.060996</td>\n",
       "      <td>0.454608</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.886500</td>\n",
       "      <td>0.875052</td>\n",
       "      <td>0.111362</td>\n",
       "      <td>0.579949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038895</td>\n",
       "      <td>0.044487</td>\n",
       "      <td>0.667746</td>\n",
       "      <td>0.847069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105628</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458212</td>\n",
       "      <td>0.409835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_logarithm_firstorder_InterquartileRange  \\\n",
       "0                                      0.014132   \n",
       "1                                      0.020424   \n",
       "2                                      0.014544   \n",
       "3                                      0.307839   \n",
       "4                                      0.086327   \n",
       "\n",
       "   body_squareroot_firstorder_InterquartileRange  \\\n",
       "0                                       0.013588   \n",
       "1                                       0.017036   \n",
       "2                                       0.013270   \n",
       "3                                       0.309810   \n",
       "4                                       0.081392   \n",
       "\n",
       "   body_squareroot_firstorder_Range  body_wavelet-HLH_firstorder_Skewness  \\\n",
       "0                          0.354126                              0.475221   \n",
       "1                          0.000257                              0.627934   \n",
       "2                          0.123973                              0.610127   \n",
       "3                          0.330353                              0.670973   \n",
       "4                          0.060996                              0.454608   \n",
       "\n",
       "   body_wavelet-HLH_glszm_HighGrayLevelZoneEmphasis  \\\n",
       "0                                          0.479053   \n",
       "1                                          0.460317   \n",
       "2                                          0.239766   \n",
       "3                                          0.555556   \n",
       "4                                          0.494949   \n",
       "\n",
       "   body_wavelet-HLH_glszm_LowGrayLevelZoneEmphasis  \\\n",
       "0                                         0.520947   \n",
       "1                                         0.539683   \n",
       "2                                         0.760234   \n",
       "3                                         0.444444   \n",
       "4                                         0.505051   \n",
       "\n",
       "   body_wavelet-HLL_gldm_DependenceEntropy  \\\n",
       "0                                 0.760130   \n",
       "1                                 0.894294   \n",
       "2                                 0.727060   \n",
       "3                                 0.854749   \n",
       "4                                 0.886500   \n",
       "\n",
       "   body_wavelet-LHL_gldm_DependenceEntropy  \\\n",
       "0                                 0.746909   \n",
       "1                                 0.907272   \n",
       "2                                 0.663205   \n",
       "3                                 0.865872   \n",
       "4                                 0.875052   \n",
       "\n",
       "   body_wavelet-LLL_gldm_LargeDependenceHighGrayLevelEmphasis  \\\n",
       "0                                           0.149618            \n",
       "1                                           0.092708            \n",
       "2                                           0.149217            \n",
       "3                                           0.109035            \n",
       "4                                           0.111362            \n",
       "\n",
       "   pet_exponential_firstorder_Minimum  ...  \\\n",
       "0                            0.460265  ...   \n",
       "1                            0.447542  ...   \n",
       "2                            0.558188  ...   \n",
       "3                            0.538966  ...   \n",
       "4                            0.579949  ...   \n",
       "\n",
       "   pet_wavelet-LLH_firstorder_Maximum  pet_wavelet-LLH_firstorder_Range  \\\n",
       "0                            0.233283                          0.234292   \n",
       "1                            0.240019                          0.281370   \n",
       "2                            0.181982                          0.194694   \n",
       "3                            0.063857                          0.078791   \n",
       "4                            0.038895                          0.044487   \n",
       "\n",
       "   pet_wavelet-LLH_glcm_ClusterShade  pet_wavelet-LLH_glcm_ClusterTendency  \\\n",
       "0                           0.636539                              0.966459   \n",
       "1                           0.978057                              0.743770   \n",
       "2                           0.664476                              0.889245   \n",
       "3                           0.851609                              0.844732   \n",
       "4                           0.667746                              0.847069   \n",
       "\n",
       "   pet_wavelet-LLH_glcm_JointEnergy  pet_wavelet-LLH_glcm_JointEntropy  \\\n",
       "0                          0.082246                           0.871629   \n",
       "1                          0.327587                           0.655821   \n",
       "2                          0.028861                           0.956205   \n",
       "3                          0.153114                           0.832072   \n",
       "4                          0.000000                           1.000000   \n",
       "\n",
       "   pet_wavelet-LLH_glcm_MaximumProbability  pet_wavelet-LLH_glcm_SumEntropy  \\\n",
       "0                                 0.134636                         0.921615   \n",
       "1                                 0.515865                         0.705530   \n",
       "2                                 0.121389                         0.974795   \n",
       "3                                 0.326818                         0.870278   \n",
       "4                                 0.105628                         1.000000   \n",
       "\n",
       "   pet_wavelet-LLH_gldm_LargeDependenceLowGrayLevelEmphasis  \\\n",
       "0                                           0.651405          \n",
       "1                                           0.810247          \n",
       "2                                           0.591208          \n",
       "3                                           0.708948          \n",
       "4                                           0.458212          \n",
       "\n",
       "   pet_wavelet-LLH_glszm_ZoneEntropy  \n",
       "0                           0.929798  \n",
       "1                           0.584442  \n",
       "2                           0.639288  \n",
       "3                           0.571515  \n",
       "4                           0.409835  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ac99e-29bc-4a49-b68b-2beca04e4b10",
   "metadata": {},
   "source": [
    "### II. Búsqueda de los mejores hiperparámetros del modelo con Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8f0dca2-1d3e-410b-b420-1c908d711416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "#X = sm_radiometrics.drop(columns=['EGFR'])\n",
    "#y = sm_radiometrics['EGFR']\n",
    "\n",
    "# gridsearch\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "    'criterion': [\"gini\", \"entropy\"],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50, 100],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_split': [2, 5, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 2, 4, 10, 20],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rf_model, param_grid)\n",
    "clf.fit(X, y)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "best_params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37d59569-6ade-443a-9d9c-34ff2a34408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.8113300492610838\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e208a-2a6c-4f69-a973-74d3abb17ac9",
   "metadata": {},
   "source": [
    "### III. Evaluación inicial del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "725da9d9-17a9-4dde-b4dc-69c6261007fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds for cross-validation\n",
    "k_folds = 3\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c312037d-7eb2-468d-aeb6-5ec5bb9757fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Results:\n",
      "Accuracy: 1.0\n",
      "AUC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "\n",
      "Mean Testing Results:\n",
      "Accuracy: 0.7628546099290779\n",
      "AUC: 0.6583727524158466\n",
      "Precision: 0.41111111111111115\n",
      "Recall: 0.14305555555555557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initial model performance\n",
    "initial_results = []\n",
    "training_results = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Train a RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    #gb_model = GradientBoostingClassifier(random_state=42, learning_rate=0.5, n_estimators=1000)\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    training_results.append(evaluate_model(rf_model, X_train, y_train))\n",
    "    initial_results.append(evaluate_model(rf_model, X_test, y_test))\n",
    "\n",
    "\n",
    "# Calculate mean results for training and testing\n",
    "training_average_results = np.mean(training_results, axis=0)\n",
    "initial_average_results = np.mean(initial_results, axis=0)\n",
    "\n",
    "# Print mean training results\n",
    "print(\"Mean Training Results:\")\n",
    "print(f\"Accuracy: {training_average_results[0]}\")\n",
    "print(f\"AUC: {training_average_results[1]}\")\n",
    "print(f\"Precision: {training_average_results[2]}\")\n",
    "print(f\"Recall: {training_average_results[3]}\")\n",
    "\n",
    "# Print mean testing results\n",
    "print(\"\\nMean Testing Results:\")\n",
    "print(f\"Accuracy: {initial_average_results[0]}\")\n",
    "print(f\"AUC: {initial_average_results[1]}\")\n",
    "print(f\"Precision: {initial_average_results[2]}\")\n",
    "print(f\"Recall: {initial_average_results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf2706-bfb5-4302-82d4-bf8a04032f4d",
   "metadata": {},
   "source": [
    "### IV. Selección de características con *backward selection*\n",
    "Se filtran las características menos relevantes de acuerdo al proceso de *backward selection* usando el modelo *RandomForestClassifier* con KFold con *k=5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e467946-0945-4c5e-b1f2-629ecbfd5a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m X[current_features]\u001b[38;5;241m.\u001b[39miloc[train_index], X[current_features]\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     21\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m---> 23\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mbest_params\u001b[49m)\n\u001b[1;32m     24\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     25\u001b[0m accuracy_per_fold\u001b[38;5;241m.\u001b[39mappend(evaluate_model(rf_model, X_test, y_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Backward feature selection with k-fold cross-validation\n",
    "selected_features = list(X.columns)\n",
    "print(len(selected_features))\n",
    "\n",
    "prev_accuracy = np.inf  # Initialize with a high value\n",
    "tolerance = 1e-2  # Define a tolerance for stopping criterion\n",
    "\n",
    "for _ in range(len(selected_features) - 1):\n",
    "    # Store current performance\n",
    "    best_accuracy = 0\n",
    "    best_results = None\n",
    "    feature_to_remove = None\n",
    "\n",
    "    # Try removing each feature and evaluate the model using k-fold cross-validation\n",
    "    for feature in selected_features:\n",
    "        current_features = [f for f in selected_features if f != feature]\n",
    "        accuracy_per_fold = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[current_features].iloc[train_index], X[current_features].iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            rf_model = RandomForestClassifier(random_state=42, **best_params)\n",
    "            rf_model.fit(X_train, y_train)\n",
    "            accuracy_per_fold.append(evaluate_model(rf_model, X_test, y_test))\n",
    "\n",
    "        # Update best feature to remove\n",
    "        if np.mean(accuracy_per_fold, axis=0)[0] > best_accuracy:\n",
    "            best_accuracy = np.mean(accuracy_per_fold, axis=0)[0]\n",
    "            best_results = np.mean(accuracy_per_fold, axis=0)\n",
    "            feature_to_remove = feature\n",
    "\n",
    "    # Stop if the change in accuracy is below the tolerance\n",
    "    if prev_accuracy - best_accuracy < tolerance:\n",
    "        print(\"Stopping criterion reached. No significant improvement.\")\n",
    "        break\n",
    "\n",
    "    #prev_accuracy = best_accuracy\n",
    "\n",
    "    # Remove the least important feature\n",
    "    selected_features.remove(feature_to_remove)\n",
    "    print(f\"Removed feature {feature_to_remove}, Current results: {best_results}\")\n",
    "\n",
    "# Final selected features\n",
    "print(\"Final selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f061b0-1489-412b-8670-74e5a9ce95e1",
   "metadata": {},
   "source": [
    "### Entrenamiento en datos de Stanford y resultados en el conjunto de Santa Maria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b441fafa-f869-41b9-91bf-6e2881642277",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv('santamaria_data_all__binwidth_15_sigma_[1, 2, 3]_normalize_True.csv')\n",
    "\n",
    "original_drop_columns = ['SEXO_MASCULINO', 'EDAD', 'PATIENT_ID', 'FECHA_CIRUGIA', 'BIOPSIA_QX_PULMONAR', 'BIOPSIA_FBC-EBUS', 'BIOPSIA_OTRO_SITIO', 'RESULTADO_BP', 'BP_COMPLETA', 'HISTOLOGIA', 'MUTACION_EGFR', 'MUTACION_PDL-1', 'MUTACION_ROS', 'RECIDIVA', 'COMENTARIO', '3D_TORAX_SEG', 'PET_SEG', 'BODY_CT_SEG']\n",
    "images_columns = ['diagnostics_Mask-original_CenterOfMass', 'diagnostics_Configuration_EnabledImageTypes', 'diagnostics_Configuration_Settings', \n",
    "                  'diagnostics_Image-original_Dimensionality', 'diagnostics_Mask-original_BoundingBox', \n",
    "                  'diagnostics_Versions_PyRadiomics', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Image-original_Hash', \n",
    "                  'diagnostics_Image-original_Size', 'diagnostics_Image-original_Spacing', 'diagnostics_Mask-original_Hash', \n",
    "                  'diagnostics_Mask-original_Size', 'diagnostics_Mask-original_Spacing', 'diagnostics_Versions_Numpy', \n",
    "                  'diagnostics_Versions_PyWavelet', 'diagnostics_Versions_Python', 'diagnostics_Versions_SimpleITK', \n",
    "                  'diagnostics_Image-interpolated_Size', 'diagnostics_Image-interpolated_Spacing', 'diagnostics_Mask-interpolated_BoundingBox', \n",
    "                  'diagnostics_Mask-interpolated_CenterOfMass', 'diagnostics_Mask-interpolated_CenterOfMassIndex', 'diagnostics_Mask-interpolated_Size',\n",
    "                  'diagnostics_Mask-interpolated_Spacing']\n",
    "\n",
    "exam_types = ['body_', 'pet_', 'torax3d_']\n",
    "images_columns = [exam + s for s in images_columns for exam in exam_types]\n",
    "\n",
    "# extra columns that are not relevant\n",
    "extra_columns = ['ALK', 'MUTACION_ALK', 'PDL-1','ROS', 'ADENOPATIAS', 'STAGE', 'IV CONTRAST', 'TAMAÑO_BP_mm', 'TAMAÑO_CT_mm']\n",
    "\n",
    "drop_columns = original_drop_columns+images_columns+extra_columns\n",
    "test_ds = test_ds.drop(columns=drop_columns)\n",
    "test_ds = test_ds.drop(index=34)\n",
    "\n",
    "# Separate features and target\n",
    "X_test = test_ds.drop(columns=['EGFR'])\n",
    "X_test = X_test[X.columns]\n",
    "y_test = test_ds['EGFR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea63ae21-9e48-4287-b4ce-1ff82171b0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 1.0, 1.0)\n",
      "\n",
      "(0.4117647058823529, 0.3712121212121212, 0.36666666666666664, 0.9166666666666666)\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=15)\n",
    "rf_model.fit(X, y)\n",
    "print(evaluate_model(rf_model, X, y))\n",
    "print()\n",
    "print(evaluate_model(rf_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f06227-23f9-417a-8d02-60889af4c84c",
   "metadata": {},
   "source": [
    "## Extra - Aplicación de técnica de selección de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae4258-7edf-477e-922f-2bad159a11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdfs\n",
    "\n",
    "# Separate features and target\n",
    "X = sm_radiometrics.drop(columns=['EGFR']).to_numpy()\n",
    "y = sm_radiometrics['EGFR'].astype(np.intc).to_numpy()\n",
    "\n",
    "result = mdfs.run(X, y, seed=0, n_contrast=50, dimensions=2, divisions=2, discretizations=6,\n",
    "        range_=None, pc_xi=0.25, p_adjust_method='fdr_tsbh', level=0.3)\n",
    "\n",
    "relevant_var = result['relevant_variables']\n",
    "\n",
    "# Get the names of relevant variables from the original DataFrame\n",
    "original_column_names = sm_radiometrics.drop(columns=['EGFR']).columns\n",
    "relevant_column_names = original_column_names[relevant_var]\n",
    "\n",
    "# Create a new DataFrame with the relevant variables and original column names\n",
    "X = pd.DataFrame(X[:, relevant_var], columns=relevant_column_names)\n",
    "y = sm_radiometrics['EGFR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c8753-8dae-4920-8f00-f99925f86175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds for cross-validation\n",
    "k_folds = 3\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=4)\n",
    "\n",
    "# Initial model performance\n",
    "initial_results = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Train a RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(random_state=42, **best_params)\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    initial_results.append(evaluate_model(rf_model, X_test, y_test))\n",
    "\n",
    "# Print initial results\n",
    "initial_average_results = np.mean(initial_results, axis=0)\n",
    "\n",
    "print(\"Initial Results:\")\n",
    "print(f\"Accuracy: {initial_average_results[0]}\")\n",
    "print(f\"AUC: {initial_average_results[1]}\")\n",
    "print(f\"Precision: {initial_average_results[2]}\")\n",
    "print(f\"Recall: {initial_average_results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66152817-f740-46a4-a8d7-2208273b6ae2",
   "metadata": {},
   "source": [
    "### Preguntas\n",
    "- Considerar las características mas estables.\n",
    "- Chest-ct contrast, PET-CT contrast, columna de 1 para sm.\n",
    "- Considerar metodos de seleccion de variables de multidimensionalidad.\n",
    "- Reportar resultados en Cross-validation Santa Maria, Stanford y entre ellos.\n",
    "\n",
    "\n",
    "- Revisar el procesamiento y aplicación del excel (filtros, normalización y otros) para la configuración del extractor - comparar con el paper de Hector.\n",
    "- Consultar si las imágenes PET de los resultados del paper se realiza la normalización con el PET de liver.\n",
    "- Se tienen que filtrar las columnas de torax3d porque para algunos pacientes no está aquella información.\n",
    "\n",
    "### Falta\n",
    "- Implementar para todos los filtros posibles.\n",
    "- Normalizar imágenes PET (creo).\n",
    "- hyperparameter search was performed with gridsearch and the performance metrics were\n",
    "calculated with 100 repetitions of 5-fold cross-validation.\n",
    "- Implementar lo anterior para que sea entrenado y validado en Stanford, para luego testear en Santa María."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f63f5e-90f1-4bea-a59e-75f74c1ccedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
